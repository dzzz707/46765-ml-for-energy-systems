{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-15T09:30:31.825103Z",
     "start_time": "2024-10-15T09:30:31.808255Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.model_selection import GridSearchCV"
   ],
   "outputs": [],
   "execution_count": 96
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-15T08:58:55.620642Z",
     "start_time": "2024-10-15T08:58:55.558403Z"
    }
   },
   "source": [
    "file_path = 'Data assignment 1/Feature data.csv'\n",
    "data = pd.read_csv(file_path)"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "In this step the different features are scaled "
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-15T08:58:55.659032Z",
     "start_time": "2024-10-15T08:58:55.621651Z"
    }
   },
   "source": [
    "\n",
    "scaler_standard = StandardScaler()\n",
    "scaler_minmax = MinMaxScaler()\n",
    "\n",
    "### 1. Standard Scaling for wind speed and temperature\n",
    "data['Mean wind speed'] = scaler_standard.fit_transform(data[['Mean wind speed']])\n",
    "data['Maximum temperature'] = scaler_standard.fit_transform(data[['Maximum temperature']])\n",
    "\n",
    "### 2. Wind Direction (convert to sin and cos components)\n",
    "data['Wind direction sin'] = np.sin(np.deg2rad(data['Mean wind direction']))\n",
    "data['Wind direction cos'] = np.cos(np.deg2rad(data['Mean wind direction']))\n",
    "\n",
    "### 3. Normalize Power Production \n",
    "nominal_capacity = 30000 # production capacity is 30 MW, unit of power production is kW so nominal capacity is 30000\n",
    "data['AKI Kalby Active Power'] = data['AKI Kalby Active Power'] / nominal_capacity\n",
    "\n",
    "# Dropping the original wind direction after transformation\n",
    "data = data.drop('Mean wind direction', axis=1)"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-15T08:58:55.688263Z",
     "start_time": "2024-10-15T08:58:55.659032Z"
    }
   },
   "source": [
    "# Make sure datetime is set as the index\n",
    "data['datetime'] = pd.to_datetime(data['datetime'])\n",
    "data.set_index('datetime', inplace=True)"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-15T08:58:55.700792Z",
     "start_time": "2024-10-15T08:58:55.688263Z"
    }
   },
   "source": [
    "# set target and features, and remove non-numeric columns\n",
    "target_column = 'AKI Kalby Active Power'\n",
    "features = data.select_dtypes(include=[np.number]).drop(columns=[target_column])"
   ],
   "outputs": [],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-15T08:58:55.731495Z",
     "start_time": "2024-10-15T08:58:55.700792Z"
    }
   },
   "source": [
    "data"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                     AKI Kalby Active Power  Maximum temperature  \\\n",
       "datetime                                                           \n",
       "2022-01-01 00:00:00               -0.063118            -0.457945   \n",
       "2022-01-01 01:00:00               -0.055728            -0.457945   \n",
       "2022-01-01 02:00:00               -0.095724            -0.503187   \n",
       "2022-01-01 03:00:00               -0.063726            -0.518268   \n",
       "2022-01-01 04:00:00               -0.029392            -0.473025   \n",
       "...                                     ...                  ...   \n",
       "2022-12-31 19:00:00               -0.148665             0.009559   \n",
       "2022-12-31 20:00:00               -0.153192             0.039721   \n",
       "2022-12-31 21:00:00               -0.120257             0.039721   \n",
       "2022-12-31 22:00:00               -0.103334            -0.065844   \n",
       "2022-12-31 23:00:00               -0.117154            -0.065844   \n",
       "\n",
       "                     Mean wind speed  Wind direction sin  Wind direction cos  \n",
       "datetime                                                                      \n",
       "2022-01-01 00:00:00         0.868655           -0.998630       -5.233596e-02  \n",
       "2022-01-01 01:00:00         0.382418           -0.956305       -2.923717e-01  \n",
       "2022-01-01 02:00:00         0.756447           -0.994522       -1.045285e-01  \n",
       "2022-01-01 03:00:00         0.494627           -1.000000       -1.836970e-16  \n",
       "2022-01-01 04:00:00         0.307612           -0.951057        3.090170e-01  \n",
       "...                              ...                 ...                 ...  \n",
       "2022-12-31 19:00:00         1.953338           -0.656059       -7.547096e-01  \n",
       "2022-12-31 20:00:00         1.467101           -0.731354       -6.819984e-01  \n",
       "2022-12-31 21:00:00         1.504504           -0.681998       -7.313537e-01  \n",
       "2022-12-31 22:00:00         1.242684           -0.798636       -6.018150e-01  \n",
       "2022-12-31 23:00:00         0.868655           -0.743145       -6.691306e-01  \n",
       "\n",
       "[7813 rows x 5 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AKI Kalby Active Power</th>\n",
       "      <th>Maximum temperature</th>\n",
       "      <th>Mean wind speed</th>\n",
       "      <th>Wind direction sin</th>\n",
       "      <th>Wind direction cos</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>datetime</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2022-01-01 00:00:00</th>\n",
       "      <td>-0.063118</td>\n",
       "      <td>-0.457945</td>\n",
       "      <td>0.868655</td>\n",
       "      <td>-0.998630</td>\n",
       "      <td>-5.233596e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-01 01:00:00</th>\n",
       "      <td>-0.055728</td>\n",
       "      <td>-0.457945</td>\n",
       "      <td>0.382418</td>\n",
       "      <td>-0.956305</td>\n",
       "      <td>-2.923717e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-01 02:00:00</th>\n",
       "      <td>-0.095724</td>\n",
       "      <td>-0.503187</td>\n",
       "      <td>0.756447</td>\n",
       "      <td>-0.994522</td>\n",
       "      <td>-1.045285e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-01 03:00:00</th>\n",
       "      <td>-0.063726</td>\n",
       "      <td>-0.518268</td>\n",
       "      <td>0.494627</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.836970e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-01 04:00:00</th>\n",
       "      <td>-0.029392</td>\n",
       "      <td>-0.473025</td>\n",
       "      <td>0.307612</td>\n",
       "      <td>-0.951057</td>\n",
       "      <td>3.090170e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-31 19:00:00</th>\n",
       "      <td>-0.148665</td>\n",
       "      <td>0.009559</td>\n",
       "      <td>1.953338</td>\n",
       "      <td>-0.656059</td>\n",
       "      <td>-7.547096e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-31 20:00:00</th>\n",
       "      <td>-0.153192</td>\n",
       "      <td>0.039721</td>\n",
       "      <td>1.467101</td>\n",
       "      <td>-0.731354</td>\n",
       "      <td>-6.819984e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-31 21:00:00</th>\n",
       "      <td>-0.120257</td>\n",
       "      <td>0.039721</td>\n",
       "      <td>1.504504</td>\n",
       "      <td>-0.681998</td>\n",
       "      <td>-7.313537e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-31 22:00:00</th>\n",
       "      <td>-0.103334</td>\n",
       "      <td>-0.065844</td>\n",
       "      <td>1.242684</td>\n",
       "      <td>-0.798636</td>\n",
       "      <td>-6.018150e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-31 23:00:00</th>\n",
       "      <td>-0.117154</td>\n",
       "      <td>-0.065844</td>\n",
       "      <td>0.868655</td>\n",
       "      <td>-0.743145</td>\n",
       "      <td>-6.691306e-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7813 rows × 5 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-15T08:58:55.754383Z",
     "start_time": "2024-10-15T08:58:55.731495Z"
    }
   },
   "source": [
    "# split the data\n",
    "X = data.drop(columns=[target_column])\n",
    "y = data[target_column]\n",
    "\n",
    "split_data= TimeSeriesSplit(n_splits=3, test_size=int(0.2*len(data)))\n",
    "for train_index, test_index in split_data.split(X):\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    \n",
    "print(\"TRAIN indices:\", train_index, \"TEST indices:\", test_index)\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"X_test shape:\", X_test.shape)\n",
    "print(\"y_train shape:\", y_train.shape)\n",
    "print(\"y_test shape:\", y_test.shape)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN indices: [   0    1    2 ... 6248 6249 6250] TEST indices: [6251 6252 6253 ... 7810 7811 7812]\n",
      "X_train shape: (6251, 4)\n",
      "X_test shape: (1562, 4)\n",
      "y_train shape: (6251,)\n",
      "y_test shape: (1562,)\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3 Linear regression"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-15T08:58:55.764449Z",
     "start_time": "2024-10-15T08:58:55.754383Z"
    }
   },
   "source": [
    "# Step 3.1 Please show that these two methods end up with the same solution.\n",
    "X_sample = features[:100]\n",
    "y_sample = data[target_column][:100]"
   ],
   "outputs": [],
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-15T08:58:55.778270Z",
     "start_time": "2024-10-15T08:58:55.764449Z"
    }
   },
   "source": [
    "# Sequential split (shuffle=False)\n",
    "X_sample_train, X_sample_test, y_sample_train, y_sample_test = train_test_split(\n",
    "    X_sample, y_sample, test_size=0.2, shuffle=False, random_state=42)\n",
    "\n",
    "# Adding a column of ones to X_sample for the bias term and converting to NumPy array\n",
    "X_sample_train_with_bias = np.c_[np.ones(X_sample_train.shape[0]), X_sample_train].astype(float)\n",
    "X_sample_test_with_bias = np.c_[np.ones(X_sample_test.shape[0]), X_sample_test].astype(float)\n",
    "\n",
    "# Ensure y_sample_train is also a NumPy array\n",
    "y_sample_train = np.array(y_sample_train).astype(float)"
   ],
   "outputs": [],
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-15T08:58:57.233572Z",
     "start_time": "2024-10-15T08:58:55.778270Z"
    }
   },
   "source": [
    "# Gradient Descent function\n",
    "def gradient_descent(X, y, learning_rate=0.01, epochs=100000):\n",
    "    m, n = X.shape\n",
    "    theta = np.zeros(n)\n",
    "    for _ in range(epochs):\n",
    "        y_pred = X @ theta\n",
    "        gradients = (1/m) * X.T @ (y_pred - y)\n",
    "        theta -= learning_rate * gradients\n",
    "    return theta\n",
    "\n",
    "theta_gd = gradient_descent(X_sample_train_with_bias, y_sample_train)\n",
    "\n",
    "# Predictions using Gradient Descent\n",
    "y_pred_gd = X_sample_test_with_bias @ theta_gd"
   ],
   "outputs": [],
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-15T08:58:57.534123Z",
     "start_time": "2024-10-15T08:58:57.233572Z"
    }
   },
   "source": [
    "# Closed-form solution \n",
    "theta_closed_form = np.linalg.inv(X_sample_train_with_bias.T @ X_sample_train_with_bias) @ X_sample_train_with_bias.T @ y_sample_train\n",
    "\n",
    "# Predictions using closed-form solution\n",
    "y_pred_closed_form = X_sample_test_with_bias @ theta_closed_form"
   ],
   "outputs": [],
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-15T08:58:57.547467Z",
     "start_time": "2024-10-15T08:58:57.534123Z"
    }
   },
   "source": [
    "# mse calculation\n",
    "mse_gd = mean_squared_error(y_sample_test, y_pred_gd)\n",
    "mse_closed_form = mean_squared_error(y_sample_test, y_pred_closed_form)\n",
    "\n",
    "print(f\"Gradient Descent θ: {[f'{x:.5f}' for x in theta_gd]}\")\n",
    "print(f\"Closed-Form θ: {[f'{x:.5f}' for x in theta_closed_form]}\")\n",
    "print(f\"Gradient Descent MSE: {mse_gd:.5f}\")\n",
    "print(f\"Closed-Form MSE: {mse_closed_form:.5f}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Descent θ: ['-0.03789', '0.02592', '-0.04119', '0.01152', '0.01116']\n",
      "Closed-Form θ: ['-0.03789', '0.02592', '-0.04119', '0.01152', '0.01116']\n",
      "Gradient Descent MSE: 0.00099\n",
      "Closed-Form MSE: 0.00099\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-15T08:58:57.580788Z",
     "start_time": "2024-10-15T08:58:57.547467Z"
    }
   },
   "source": [
    "# Step 3.2: Use the full dataset and closed form solution\n",
    "X_large_sample, X_large_test_sample, y_large_sample, y_large_test_sample = train_test_split(features, data[target_column], test_size=0.2, random_state=42)\n",
    "\n",
    "# Adding a column of ones for the bias term in the large sample\n",
    "X_large_sample_with_bias = np.c_[np.ones(X_large_sample.shape[0]), X_large_sample]\n",
    "X_large_test_sample_with_bias = np.c_[np.ones(X_large_test_sample.shape[0]), X_large_test_sample]\n",
    "\n",
    "# Upgrade the normal equation\n",
    "theta_large_sample = np.linalg.inv(X_large_sample_with_bias.T @ X_large_sample_with_bias) @ X_large_sample_with_bias.T @ y_large_sample\n",
    "theta_large_sample_rounded = np.round(theta_large_sample, 5)\n",
    "\n",
    "print(f\"Step 3.2: Closed-form solution training complete on the larger sample.\")\n",
    "print(f\"Coefficients: {[f'{x:.5f}' for x in theta_large_sample_rounded]}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 3.2: Closed-form solution training complete on the larger sample.\n",
      "Coefficients: ['-0.04394', '0.00016', '-0.03909', '0.00591', '0.00366']\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-15T08:58:57.604789Z",
     "start_time": "2024-10-15T08:58:57.580788Z"
    }
   },
   "source": [
    "# Step 3.3: Verify your model using the testing dataset and appropriate evaluation metrics\n",
    "y_large_pred_closed_form = X_large_test_sample_with_bias @ theta_large_sample\n",
    "\n",
    "mse = mean_squared_error(y_large_test_sample, y_large_pred_closed_form)\n",
    "mae = mean_absolute_error(y_large_test_sample, y_large_pred_closed_form)\n",
    "r2 = r2_score(y_large_test_sample, y_large_pred_closed_form)\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "print(f\"Step 3.3: Model evaluation on the testing dataset:\")\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse:.5f}\")\n",
    "print(f\"Mean Squared Error (MSE): {mse:.5f}\")\n",
    "print(f\"Mean Absolute Error (MAE): {mae:.5f}\")\n",
    "print(f\"R-squared: {r2:.5f}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 3.3: Model evaluation on the testing dataset:\n",
      "Root Mean Squared Error (RMSE): 0.03016\n",
      "Mean Squared Error (MSE): 0.00091\n",
      "Mean Absolute Error (MAE): 0.02294\n",
      "R-squared: 0.64752\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4 Non-linear Regression\n",
    "\n",
    "In Step 1's formulation, if the price $\\lambda$ is treated as a constant and the actual value p is known, the entire formula simplifies into a function dependent on the predicted value $\\hat{p}_t$. This implies that the problem can be reframed as an optimization task concerning the prediction of $\\hat{p}_t$. Given this perspective, extending the linear regression model from Step 3 by incorporating nonlinear features to predict $\\hat{p}_t$ effectively transforms the problem into a nonlinear regression for Step 1's objective. Therefore, performing nonlinear regression on the prediction model of $\\hat{p}_t$ inherently satisfies the requirements of the nonlinear extension outlined in Step 4."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-15T08:58:57.627386Z",
     "start_time": "2024-10-15T08:58:57.604789Z"
    }
   },
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression"
   ],
   "outputs": [],
   "execution_count": 15
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-15T08:58:57.731195Z",
     "start_time": "2024-10-15T08:58:57.627386Z"
    }
   },
   "source": [
    "# Step 4.1: Add polynomial features (squared and cubic terms)\n",
    "poly = PolynomialFeatures(degree=3, include_bias=False) \n",
    "X_poly = poly.fit_transform(features)\n",
    "\n",
    "# Convert to DataFrame with correct column names\n",
    "X_poly_df = pd.DataFrame(X_poly, columns=poly.get_feature_names_out(features.columns))\n",
    "\n",
    "# Split the polynomial feature data\n",
    "X_train_poly, X_test_poly, y_train_poly, y_test_poly = train_test_split(X_poly_df, data[target_column], test_size=0.2, random_state=42)\n",
    "\n",
    "# Fit linear regression model on the polynomial features\n",
    "linear_model_poly = LinearRegression()\n",
    "linear_model_poly.fit(X_train_poly, y_train_poly)\n",
    "\n",
    "# Predict on the testing data\n",
    "y_pred_poly = linear_model_poly.predict(X_test_poly)"
   ],
   "outputs": [],
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-15T08:58:57.747447Z",
     "start_time": "2024-10-15T08:58:57.731195Z"
    }
   },
   "source": [
    "# evaluate the performance\n",
    "mse_poly = mean_squared_error(y_test_poly, y_pred_poly)\n",
    "mae_poly = mean_absolute_error(y_test_poly, y_pred_poly)\n",
    "r2_poly = r2_score(y_test_poly, y_pred_poly)\n",
    "rmse_poly = np.sqrt(mse_poly)\n",
    "\n",
    "print(f\"Nonlinear model evaluation on the testing dataset:\")\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse_poly:.4f}\")\n",
    "print(f\"Mean Squared Error (MSE): {mse_poly:.4f}\")\n",
    "print(f\"Mean Absolute Error (MAE): {mae_poly:.4f}\")\n",
    "print(f\"R-squared: {r2_poly:.4f}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nonlinear model evaluation on the testing dataset:\n",
      "Root Mean Squared Error (RMSE): 0.0278\n",
      "Mean Squared Error (MSE): 0.0008\n",
      "Mean Absolute Error (MAE): 0.0204\n",
      "R-squared: 0.7014\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For step 4.2, the method of locally weighted least squares will be used, as tought in the lecture. Different kernels will be compared and the best one will be chosen based on evaluating the performance on the test data."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-15T08:58:57.765994Z",
     "start_time": "2024-10-15T08:58:57.747447Z"
    }
   },
   "source": [
    "def gaussian(t):\n",
    "    return np.exp(-0.5 * t**2) / np.sqrt(2 * np.pi)\n",
    "\n",
    "def epanechnikov(t):\n",
    "    res = np.zeros_like(t)\n",
    "    res[np.abs(t) <= 1] = 0.75 * (1 - t[np.abs(t) <= 1]**2)\n",
    "    return res\n",
    "\n",
    "def tricube(t):\n",
    "    res = np.zeros_like(t)\n",
    "    res[np.abs(t) <= 1] = (70 / 81) * (1 - np.abs(t[np.abs(t) <= 1])**3)**3\n",
    "    return res\n",
    "\n",
    "def uniform(t, p=0.2):\n",
    "    return np.zeros_like(t) + p\n",
    "\n",
    "def triangle(t):\n",
    "    res = np.zeros_like(t)\n",
    "    res[np.abs(t) <= 1] = 1 - np.abs(t[np.abs(t) <= 1])\n",
    "    return res"
   ],
   "outputs": [],
   "execution_count": 18
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-15T08:58:57.778638Z",
     "start_time": "2024-10-15T08:58:57.769007Z"
    }
   },
   "source": [
    "# Locally Weighted Least Squares implementation\n",
    "def lwls_predict(X_train, y_train, X_test, kernel_func, tau=0.1):\n",
    "    y_pred = np.zeros(len(X_test))\n",
    "\n",
    "    for i, x in enumerate(X_test):\n",
    "        distances = np.linalg.norm(X_train - x, axis=1)  # Compute distances\n",
    "        weights = kernel_func(distances / tau)  # Apply kernel function\n",
    "        W = np.diag(weights)  # Create diagonal weight matrix\n",
    "\n",
    "        # Weighted Least Squares computation\n",
    "        XTWX = X_train.T @ W @ X_train  # X^T W X\n",
    "        XTWy = X_train.T @ W @ y_train  # X^T W y\n",
    "\n",
    "        # Use np.linalg.pinv for numerical stability\n",
    "        theta = np.linalg.pinv(XTWX) @ XTWy\n",
    "\n",
    "        # Ensure x is 2D before matrix multiplication\n",
    "        y_pred[i] = np.dot(x, theta)  # Prediction for the current test sample\n",
    "\n",
    "    return y_pred"
   ],
   "outputs": [],
   "execution_count": 19
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-15T08:58:57.790597Z",
     "start_time": "2024-10-15T08:58:57.778638Z"
    }
   },
   "source": [
    "# Function to evaluate different kernels and select the best one\n",
    "def evaluate_kernels(X_train, y_train, X_test, y_test, kernels, tau=0.1):\n",
    "    mse_results = {}\n",
    "\n",
    "    for kernel_name, kernel_func in kernels.items():\n",
    "\n",
    "        y_pred = lwls_predict(X_train, y_train, X_test, kernel_func, tau=tau)\n",
    "        mse = mean_squared_error(y_test, y_pred)\n",
    "        mse_results[kernel_name] = mse\n",
    "\n",
    "    return mse_results\n",
    "\n",
    "# Example kernels (ensure these are defined somewhere in the code)\n",
    "kernels = {\n",
    "    'Gaussian': gaussian,\n",
    "    'Epanechnikov': epanechnikov,\n",
    "    'Tricube': tricube,\n",
    "    'Uniform': uniform,\n",
    "    'Triangle': triangle\n",
    "}"
   ],
   "outputs": [],
   "execution_count": 20
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-15T08:58:57.829667Z",
     "start_time": "2024-10-15T08:58:57.790597Z"
    }
   },
   "source": [
    "# Evaluate kernels on smaller data for faster results\n",
    "mse_results_small = evaluate_kernels(X_sample_train_with_bias, y_sample_train, X_sample_test_with_bias, y_sample_test, kernels)\n",
    "\n",
    "print(mse_results_small)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Gaussian': 0.017111643456072034, 'Epanechnikov': 0.015838563409984314, 'Tricube': 0.015838563409984314, 'Uniform': 0.0009889360972607534, 'Triangle': 0.015838563409984314}\n"
     ]
    }
   ],
   "execution_count": 21
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-15T09:03:17.807222Z",
     "start_time": "2024-10-15T08:58:57.832185Z"
    }
   },
   "source": [
    "# Evaluation on the kernel selected\n",
    "def evaluate_uniform(X_train, y_train, X_test, y_test, uniform, tau=0.1):\n",
    "    for kernel_name, kernel_func in uniform.items():\n",
    "        y_pred = lwls_predict(X_train, y_train, X_test, kernel_func, tau=tau)\n",
    "        \n",
    "        mse = mean_squared_error(y_test, y_pred)\n",
    "        mae_wls_uniform = mean_absolute_error(y_test, y_pred)\n",
    "        r2_wls_uniform = r2_score(y_test, y_pred)\n",
    "        rmse_wls_uniform = np.sqrt(mse)\n",
    "        \n",
    "        print(f\"{kernel_name} Kernel Results:\")\n",
    "        print(f\"Mean Squared Error (MSE): {mse}\")\n",
    "        print(f\"Mean Absolute Error (MAE): {mae_wls_uniform}\")\n",
    "        print(f\"R-squared (R2): {r2_wls_uniform}\")\n",
    "        print(f\"Root Mean Squared Error (RMSE): {rmse_wls_uniform}\")\n",
    "\n",
    "    return\n",
    "\n",
    "uniform_kernel = {\n",
    "    'Uniform': uniform\n",
    "}\n",
    "\n",
    "evaluate_uniform(X_large_sample_with_bias, y_large_sample, X_large_test_sample_with_bias, y_large_test_sample, uniform_kernel)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uniform Kernel Results:\n",
      "Mean Squared Error (MSE): 0.0009096630799356888\n",
      "Mean Absolute Error (MAE): 0.022935803113481798\n",
      "R-squared (R2): 0.6475178661281868\n",
      "Root Mean Squared Error (RMSE): 0.030160621345318616\n"
     ]
    }
   ],
   "execution_count": 22
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5 Regularization\n",
    "#### Lasso regularization\n",
    "##### linear regression\n",
    "In order to apply lasso regression there are two prerequisites.  the linear regression has to be performed and the Gradient Descent has to be calculated. \n",
    "The gradient descent is used to update the coefficients iteratively through training instances "
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-15T09:53:18.664693Z",
     "start_time": "2024-10-15T09:53:18.307228Z"
    }
   },
   "cell_type": "code",
   "source": [
    "alpha_values = {'alpha': [0.0001, 0.01, 0.1, 1, 10, 100]}\n",
    "\n",
    "# Ridge model with cross-validation\n",
    "ridge_model = Ridge()\n",
    "ridge_cv = GridSearchCV(ridge_model, param_grid=alpha_values, cv=5, scoring='neg_mean_squared_error')\n",
    "ridge_cv.fit(X_large_test_sample,y_large_test_sample)\n",
    "\n",
    "# Lasso model with cross-validation\n",
    "lasso_model = Lasso()\n",
    "lasso_cv = GridSearchCV(lasso_model, param_grid=alpha_values, cv=5, scoring='neg_mean_squared_error')\n",
    "lasso_cv.fit(X_large_test_sample,y_large_test_sample)\n",
    "\n",
    "# Get the best alpha values\n",
    "best_alpha_ridge = ridge_cv.best_params_['alpha']\n",
    "best_alpha_lasso = lasso_cv.best_params_['alpha']\n",
    "\n",
    "print(f\"Optimal alpha for Ridge with the full dataset: {best_alpha_ridge}\")\n",
    "print(f\"Optimal alpha for Lasso with the full dataset: {best_alpha_lasso}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal alpha for Ridge with the full dataset: 1\n",
      "Optimal alpha for Lasso with the full dataset: 0.0001\n"
     ]
    }
   ],
   "execution_count": 113
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-15T09:53:21.109609Z",
     "start_time": "2024-10-15T09:53:21.086511Z"
    }
   },
   "cell_type": "code",
   "source": [
    "lasso_model = Lasso(alpha=best_alpha_lasso)\n",
    "lasso_model.fit(X_large_test_sample,y_large_test_sample)\n",
    "y_pred_lasso = lasso_model.predict(X_large_test_sample)\n",
    "lasso_model.coef_"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.00056673, -0.03850683,  0.00719808,  0.0057766 ])"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 114
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-15T09:53:48.292827Z",
     "start_time": "2024-10-15T09:53:48.276243Z"
    }
   },
   "cell_type": "code",
   "source": [
    "mse_lasso = mean_squared_error(y_large_test_sample, y_pred_lasso)\n",
    "mae_lasso= mean_absolute_error(y_large_test_sample, y_pred_lasso)\n",
    "r2_lasso = r2_score(y_large_test_sample, y_pred_lasso)\n",
    "rmse_lasso = np.sqrt(mse_lasso)\n",
    "\n",
    "print(f\"Weighted Least Squares model evaluation on the testing dataset and the ridge regression with a penalty of 0.9:\")\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse_lasso:.4f}\")\n",
    "print(f\"Mean Squared Error (MSE): {mse_lasso:.4f}\")\n",
    "print(f\"Mean Absolute Error (MAE): {mae_lasso:.4f}\")\n",
    "print(f\"R-squared: {r2_lasso:.4f}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weighted Least Squares model evaluation on the testing dataset and the ridge regression with a penalty of 0.9:\n",
      "Root Mean Squared Error (RMSE): 0.0301\n",
      "Mean Squared Error (MSE): 0.0009\n",
      "Mean Absolute Error (MAE): 0.0229\n",
      "R-squared: 0.6491\n"
     ]
    }
   ],
   "execution_count": 115
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-15T09:53:51.799766Z",
     "start_time": "2024-10-15T09:53:51.768849Z"
    }
   },
   "cell_type": "code",
   "source": [
    "ridge_model = Ridge(alpha=best_alpha_ridge)\n",
    "ridge_model.fit(X_large_test_sample,y_large_test_sample)\n",
    "y_pred_ridge = ridge_model.predict(X_large_test_sample)\n",
    "ridge_model.coef_"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.00066934, -0.03855133,  0.00735763,  0.00600741])"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 116
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-15T09:53:55.162880Z",
     "start_time": "2024-10-15T09:53:55.143886Z"
    }
   },
   "cell_type": "code",
   "source": [
    "mse_ridge = mean_squared_error(y_large_test_sample, y_pred_lasso)\n",
    "mae_ridge= mean_absolute_error(y_large_test_sample, y_pred_lasso)\n",
    "r2_ridge = r2_score(y_large_test_sample, y_pred_lasso)\n",
    "rmse_ridge = np.sqrt(mse_lasso)\n",
    "\n",
    "print(f\"Weighted Least Squares model evaluation on the testing dataset and the lasso regression with a penalty of 0.001:\")\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse_ridge:.4f}\")\n",
    "print(f\"Mean Squared Error (MSE): {mse_ridge:.4f}\")\n",
    "print(f\"Mean Absolute Error (MAE): {mae_ridge:.4f}\")\n",
    "print(f\"R-squared: {r2_ridge:.4f}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weighted Least Squares model evaluation on the testing dataset and the lasso regression with a penalty of 0.001:\n",
      "Root Mean Squared Error (RMSE): 0.0301\n",
      "Mean Squared Error (MSE): 0.0009\n",
      "Mean Absolute Error (MAE): 0.0229\n",
      "R-squared: 0.6491\n"
     ]
    }
   ],
   "execution_count": 117
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": ""
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
