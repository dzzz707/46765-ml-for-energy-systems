{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-06T13:59:37.800987Z",
     "start_time": "2024-10-06T13:59:37.777824Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.impute import SimpleImputer\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score"
   ],
   "outputs": [],
   "execution_count": 18
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-06T14:00:05.133491Z",
     "start_time": "2024-10-06T14:00:05.091675Z"
    }
   },
   "source": [
    "file_path1 = r\"C:\\Users\\ilsed\\OneDrive\\Documents\\EPA\\Jaar 2\\DTU\\machine learning for energy systems\\Feature data.csv\"\n",
    "# file_path1=\"../Data assignment 1/ Feature data.csv\"\n",
    "data = pd.read_csv(file_path1)"
   ],
   "outputs": [],
   "execution_count": 20
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### Feature scaling"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this step,we used Principal Component Analysis (PCA) to select and reduce the dimensionality of the features."
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-06T14:00:07.623710Z",
     "start_time": "2024-10-06T14:00:07.586096Z"
    }
   },
   "cell_type": "code",
   "source": [
    "scaler_standard = StandardScaler()\n",
    "scaler_minmax = MinMaxScaler()\n",
    "\n",
    "### 1. Standard Scaling for wind speed and temperature\n",
    "data['Mean wind speed'] = scaler_standard.fit_transform(data[['Mean wind speed']])\n",
    "data['Maximum temperature'] = scaler_standard.fit_transform(data[['Maximum temperature']])\n",
    "\n",
    "### 2. Wind Direction (convert to sin and cos components)\n",
    "data['Wind direction sin'] = np.sin(np.deg2rad(data['Mean wind direction']))\n",
    "data['Wind direction cos'] = np.cos(np.deg2rad(data['Mean wind direction']))\n",
    "\n",
    "### 3. Normalize Power Production \n",
    "nominal_capacity = 30000 # production capacity is 30 MW, unit of power production is kW so nominal capacity is 30000\n",
    "data['AKI Kalby Active Power'] = data['AKI Kalby Active Power'] / nominal_capacity\n",
    "\n",
    "# Dropping the original wind direction after transformation\n",
    "data = data.drop('Mean wind direction', axis=1)"
   ],
   "outputs": [],
   "execution_count": 21
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-06T14:00:09.241773Z",
     "start_time": "2024-10-06T14:00:09.226684Z"
    }
   },
   "source": [
    "# set target and features\n",
    "target_column = 'AKI Kalby Active Power'\n",
    "features = data.drop(columns=[target_column])"
   ],
   "outputs": [],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-06T14:00:10.133081Z",
     "start_time": "2024-10-06T14:00:10.092370Z"
    }
   },
   "cell_type": "code",
   "source": "data",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                 datetime  AKI Kalby Active Power  Maximum temperature  \\\n",
       "0     2022-01-01 00:00:00               -0.063118            -0.457945   \n",
       "1     2022-01-01 01:00:00               -0.055728            -0.457945   \n",
       "2     2022-01-01 02:00:00               -0.095724            -0.503187   \n",
       "3     2022-01-01 03:00:00               -0.063726            -0.518268   \n",
       "4     2022-01-01 04:00:00               -0.029392            -0.473025   \n",
       "...                   ...                     ...                  ...   \n",
       "7808  2022-12-31 19:00:00               -0.148665             0.009559   \n",
       "7809  2022-12-31 20:00:00               -0.153192             0.039721   \n",
       "7810  2022-12-31 21:00:00               -0.120257             0.039721   \n",
       "7811  2022-12-31 22:00:00               -0.103334            -0.065844   \n",
       "7812  2022-12-31 23:00:00               -0.117154            -0.065844   \n",
       "\n",
       "      Mean wind speed  Wind direction sin  Wind direction cos  \n",
       "0            0.868655           -0.998630       -5.233596e-02  \n",
       "1            0.382418           -0.956305       -2.923717e-01  \n",
       "2            0.756447           -0.994522       -1.045285e-01  \n",
       "3            0.494627           -1.000000       -1.836970e-16  \n",
       "4            0.307612           -0.951057        3.090170e-01  \n",
       "...               ...                 ...                 ...  \n",
       "7808         1.953338           -0.656059       -7.547096e-01  \n",
       "7809         1.467101           -0.731354       -6.819984e-01  \n",
       "7810         1.504504           -0.681998       -7.313537e-01  \n",
       "7811         1.242684           -0.798636       -6.018150e-01  \n",
       "7812         0.868655           -0.743145       -6.691306e-01  \n",
       "\n",
       "[7813 rows x 6 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>AKI Kalby Active Power</th>\n",
       "      <th>Maximum temperature</th>\n",
       "      <th>Mean wind speed</th>\n",
       "      <th>Wind direction sin</th>\n",
       "      <th>Wind direction cos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-01-01 00:00:00</td>\n",
       "      <td>-0.063118</td>\n",
       "      <td>-0.457945</td>\n",
       "      <td>0.868655</td>\n",
       "      <td>-0.998630</td>\n",
       "      <td>-5.233596e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-01-01 01:00:00</td>\n",
       "      <td>-0.055728</td>\n",
       "      <td>-0.457945</td>\n",
       "      <td>0.382418</td>\n",
       "      <td>-0.956305</td>\n",
       "      <td>-2.923717e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-01-01 02:00:00</td>\n",
       "      <td>-0.095724</td>\n",
       "      <td>-0.503187</td>\n",
       "      <td>0.756447</td>\n",
       "      <td>-0.994522</td>\n",
       "      <td>-1.045285e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-01-01 03:00:00</td>\n",
       "      <td>-0.063726</td>\n",
       "      <td>-0.518268</td>\n",
       "      <td>0.494627</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.836970e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-01-01 04:00:00</td>\n",
       "      <td>-0.029392</td>\n",
       "      <td>-0.473025</td>\n",
       "      <td>0.307612</td>\n",
       "      <td>-0.951057</td>\n",
       "      <td>3.090170e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7808</th>\n",
       "      <td>2022-12-31 19:00:00</td>\n",
       "      <td>-0.148665</td>\n",
       "      <td>0.009559</td>\n",
       "      <td>1.953338</td>\n",
       "      <td>-0.656059</td>\n",
       "      <td>-7.547096e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7809</th>\n",
       "      <td>2022-12-31 20:00:00</td>\n",
       "      <td>-0.153192</td>\n",
       "      <td>0.039721</td>\n",
       "      <td>1.467101</td>\n",
       "      <td>-0.731354</td>\n",
       "      <td>-6.819984e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7810</th>\n",
       "      <td>2022-12-31 21:00:00</td>\n",
       "      <td>-0.120257</td>\n",
       "      <td>0.039721</td>\n",
       "      <td>1.504504</td>\n",
       "      <td>-0.681998</td>\n",
       "      <td>-7.313537e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7811</th>\n",
       "      <td>2022-12-31 22:00:00</td>\n",
       "      <td>-0.103334</td>\n",
       "      <td>-0.065844</td>\n",
       "      <td>1.242684</td>\n",
       "      <td>-0.798636</td>\n",
       "      <td>-6.018150e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7812</th>\n",
       "      <td>2022-12-31 23:00:00</td>\n",
       "      <td>-0.117154</td>\n",
       "      <td>-0.065844</td>\n",
       "      <td>0.868655</td>\n",
       "      <td>-0.743145</td>\n",
       "      <td>-6.691306e-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7813 rows × 6 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 23
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-06T13:50:19.656762Z",
     "start_time": "2024-10-06T13:50:19.649180Z"
    }
   },
   "source": [
    "# # Impute missing values using mean for numerical columns\n",
    "# imputer = SimpleImputer(strategy='mean')\n",
    "# features_imputed = imputer.fit_transform(features)\n",
    "# \n",
    "# # Check for any remaining NaNs after imputation\n",
    "# features_imputed_df = pd.DataFrame(features_imputed, columns=features.columns)\n",
    "# print(f\"Number of remaining NaNs: {features_imputed_df.isna().sum().sum()}\")\n",
    "# \n",
    "# # Drop any rows with NaN values (if any persist after imputation)\n",
    "# features_imputed_df.dropna(inplace=True)"
   ],
   "outputs": [],
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-06T13:50:20.126468Z",
     "start_time": "2024-10-06T13:50:20.116190Z"
    }
   },
   "source": [
    "# # standardize the features\n",
    "# scaler = StandardScaler()\n",
    "# features_scaled = scaler.fit_transform(features_imputed_df)"
   ],
   "outputs": [],
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-06T13:50:20.623865Z",
     "start_time": "2024-10-06T13:50:20.609964Z"
    }
   },
   "source": [
    "# # apply PCA and plotting\n",
    "# pca = PCA()\n",
    "# features_pca = pca.fit_transform(features_scaled)\n",
    "# explained_variance = pca.explained_variance_ratio_\n",
    "# cumulative_variance = explained_variance.cumsum()\n",
    "# \n",
    "# plt.figure(figsize=(10, 6))\n",
    "# plt.plot(range(1, len(cumulative_variance) + 1), cumulative_variance, marker='o', linestyle='--')\n",
    "# plt.title('Cumulative Explained Variance')\n",
    "# plt.xlabel('Number of Principal Components')\n",
    "# plt.ylabel('Cumulative Variance')\n",
    "# plt.grid()\n",
    "# plt.show()"
   ],
   "outputs": [],
   "execution_count": 11
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " A subset of the original features was selected based on their contribution to the variance in the data. Given the output above, we selected **8** principal components, which capture **over 95%** of the variance in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # determine number and reduce dimension\n",
    "# n_components = next(i for i, total_var in enumerate(cumulative_variance) if total_var >= 0.95) + 1 # 95% explained\n",
    "# \n",
    "# pca = PCA(n_components=n_components)\n",
    "# features_reduced = pca.fit_transform(features_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # convert to a dataFrame\n",
    "# features_pca_df = pd.DataFrame(features_reduced, columns=[f'PC{i+1}' for i in range(n_components)])\n",
    "# features_pca_df[target_column] = data.loc[features_imputed_df.index, target_column].values"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-06T13:50:26.460280Z",
     "start_time": "2024-10-06T13:50:26.443338Z"
    }
   },
   "source": [
    "# # Get the contribution of each principal component to the original variable\n",
    "# n_components = features_reduced.shape[1]  \n",
    "# pca_components_df = pd.DataFrame(pca.components_[:n_components], columns=features_imputed_df.columns)\n",
    "# \n",
    "# # Find the variable that contributes most to each principal component\n",
    "# top_features_per_component = []\n",
    "# for i in range(n_components):\n",
    "#     # Get the variable index with the largest absolute value for each principal component\n",
    "#     top_feature_index = np.argmax(np.abs(pca_components_df.iloc[i]))\n",
    "#     top_feature_name = features_imputed_df.columns[top_feature_index]\n",
    "#     top_features_per_component.append(top_feature_name)\n",
    "# \n",
    "# # Output the selected feature variable name\n",
    "# print(\"Name of the feature variable selected by PCA:\")\n",
    "# print(top_features_per_component)\n"
   ],
   "outputs": [],
   "execution_count": 12
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The original dataset includes actual weather data and historical windpark data. We combined these features into new composite features via PCA. Here we can see the types of the features we selected."
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": ""
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-06T13:50:32.611821Z",
     "start_time": "2024-10-06T13:50:32.600671Z"
    }
   },
   "source": "# features_pca_df",
   "outputs": [],
   "execution_count": 13
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dataset Split**: \n",
    "  - The notebook splits the dataset into training and testing sets using an 80-20 split. This means 80% of the data is used for training the model, while the remaining 20% is used for testing.\n",
    "  - This split was done using the `train_test_split` function from `scikit-learn`.\n",
    "\n",
    "**Contents of the Training and Testing Datasets**:\n",
    "  - **Training Dataset**: Contains the selected principal components as input features (`X_train`) and the target variable (`y_train`), which is the wind farm's power production.\n",
    "  - **Testing Dataset**: Contains the same input features (`X_test`) and target variable (`y_test`) as the training dataset but is reserved for evaluating the model's performance."
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-06T14:00:24.343425Z",
     "start_time": "2024-10-06T14:00:24.324216Z"
    }
   },
   "cell_type": "code",
   "source": "data.set_index('datetime', inplace=True)",
   "outputs": [],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-06T14:00:25.066209Z",
     "start_time": "2024-10-06T14:00:25.006298Z"
    }
   },
   "cell_type": "code",
   "source": "data",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                     AKI Kalby Active Power  Maximum temperature  \\\n",
       "datetime                                                           \n",
       "2022-01-01 00:00:00               -0.063118            -0.457945   \n",
       "2022-01-01 01:00:00               -0.055728            -0.457945   \n",
       "2022-01-01 02:00:00               -0.095724            -0.503187   \n",
       "2022-01-01 03:00:00               -0.063726            -0.518268   \n",
       "2022-01-01 04:00:00               -0.029392            -0.473025   \n",
       "...                                     ...                  ...   \n",
       "2022-12-31 19:00:00               -0.148665             0.009559   \n",
       "2022-12-31 20:00:00               -0.153192             0.039721   \n",
       "2022-12-31 21:00:00               -0.120257             0.039721   \n",
       "2022-12-31 22:00:00               -0.103334            -0.065844   \n",
       "2022-12-31 23:00:00               -0.117154            -0.065844   \n",
       "\n",
       "                     Mean wind speed  Wind direction sin  Wind direction cos  \n",
       "datetime                                                                      \n",
       "2022-01-01 00:00:00         0.868655           -0.998630       -5.233596e-02  \n",
       "2022-01-01 01:00:00         0.382418           -0.956305       -2.923717e-01  \n",
       "2022-01-01 02:00:00         0.756447           -0.994522       -1.045285e-01  \n",
       "2022-01-01 03:00:00         0.494627           -1.000000       -1.836970e-16  \n",
       "2022-01-01 04:00:00         0.307612           -0.951057        3.090170e-01  \n",
       "...                              ...                 ...                 ...  \n",
       "2022-12-31 19:00:00         1.953338           -0.656059       -7.547096e-01  \n",
       "2022-12-31 20:00:00         1.467101           -0.731354       -6.819984e-01  \n",
       "2022-12-31 21:00:00         1.504504           -0.681998       -7.313537e-01  \n",
       "2022-12-31 22:00:00         1.242684           -0.798636       -6.018150e-01  \n",
       "2022-12-31 23:00:00         0.868655           -0.743145       -6.691306e-01  \n",
       "\n",
       "[7813 rows x 5 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AKI Kalby Active Power</th>\n",
       "      <th>Maximum temperature</th>\n",
       "      <th>Mean wind speed</th>\n",
       "      <th>Wind direction sin</th>\n",
       "      <th>Wind direction cos</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>datetime</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2022-01-01 00:00:00</th>\n",
       "      <td>-0.063118</td>\n",
       "      <td>-0.457945</td>\n",
       "      <td>0.868655</td>\n",
       "      <td>-0.998630</td>\n",
       "      <td>-5.233596e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-01 01:00:00</th>\n",
       "      <td>-0.055728</td>\n",
       "      <td>-0.457945</td>\n",
       "      <td>0.382418</td>\n",
       "      <td>-0.956305</td>\n",
       "      <td>-2.923717e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-01 02:00:00</th>\n",
       "      <td>-0.095724</td>\n",
       "      <td>-0.503187</td>\n",
       "      <td>0.756447</td>\n",
       "      <td>-0.994522</td>\n",
       "      <td>-1.045285e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-01 03:00:00</th>\n",
       "      <td>-0.063726</td>\n",
       "      <td>-0.518268</td>\n",
       "      <td>0.494627</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.836970e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-01 04:00:00</th>\n",
       "      <td>-0.029392</td>\n",
       "      <td>-0.473025</td>\n",
       "      <td>0.307612</td>\n",
       "      <td>-0.951057</td>\n",
       "      <td>3.090170e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-31 19:00:00</th>\n",
       "      <td>-0.148665</td>\n",
       "      <td>0.009559</td>\n",
       "      <td>1.953338</td>\n",
       "      <td>-0.656059</td>\n",
       "      <td>-7.547096e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-31 20:00:00</th>\n",
       "      <td>-0.153192</td>\n",
       "      <td>0.039721</td>\n",
       "      <td>1.467101</td>\n",
       "      <td>-0.731354</td>\n",
       "      <td>-6.819984e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-31 21:00:00</th>\n",
       "      <td>-0.120257</td>\n",
       "      <td>0.039721</td>\n",
       "      <td>1.504504</td>\n",
       "      <td>-0.681998</td>\n",
       "      <td>-7.313537e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-31 22:00:00</th>\n",
       "      <td>-0.103334</td>\n",
       "      <td>-0.065844</td>\n",
       "      <td>1.242684</td>\n",
       "      <td>-0.798636</td>\n",
       "      <td>-6.018150e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-31 23:00:00</th>\n",
       "      <td>-0.117154</td>\n",
       "      <td>-0.065844</td>\n",
       "      <td>0.868655</td>\n",
       "      <td>-0.743145</td>\n",
       "      <td>-6.691306e-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7813 rows × 5 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 25
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-06T14:00:28.289596Z",
     "start_time": "2024-10-06T14:00:28.259422Z"
    }
   },
   "source": [
    "# split the data\n",
    "X = data.drop(columns=[target_column])\n",
    "y = data[target_column]\n",
    "\n",
    "split_data= TimeSeriesSplit(n_splits=3, test_size=int(0.2*len(data)))\n",
    "for train_index, test_index in split_data.split(X):\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    \n",
    "print(\"TRAIN indices:\", train_index, \"TEST indices:\", test_index)\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"X_test shape:\", X_test.shape)\n",
    "print(\"y_train shape:\", y_train.shape)\n",
    "print(\"y_test shape:\", y_test.shape)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN indices: [   0    1    2 ... 6248 6249 6250] TEST indices: [6251 6252 6253 ... 7810 7811 7812]\n",
      "X_train shape: (6251, 4)\n",
      "X_test shape: (1562, 4)\n",
      "y_train shape: (6251,)\n",
      "y_test shape: (1562,)\n"
     ]
    }
   ],
   "execution_count": 26
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3 Linear regression"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-06T13:51:05.116908Z",
     "start_time": "2024-10-06T13:51:05.052577Z"
    }
   },
   "source": [
    "# Step 3.1 Please show that these two methods end up with the same solution.\n",
    "# start with 100 datapoints  \n",
    "X_sample, X_test_sample, y_sample, y_test_sample = train_test_split(data[:100], data[target_column][:100], test_size=0.2, random_state=42)"
   ],
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_test_split' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[17], line 3\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;66;03m# Step 3.1 Please show that these two methods end up with the same solution.\u001B[39;00m\n\u001B[0;32m      2\u001B[0m \u001B[38;5;66;03m# start with 100 datapoints  \u001B[39;00m\n\u001B[1;32m----> 3\u001B[0m X_sample, X_test_sample, y_sample, y_test_sample \u001B[38;5;241m=\u001B[39m train_test_split(data[:\u001B[38;5;241m100\u001B[39m], data[target_column][:\u001B[38;5;241m100\u001B[39m], test_size\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0.2\u001B[39m, random_state\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m42\u001B[39m)\n",
      "\u001B[1;31mNameError\u001B[0m: name 'train_test_split' is not defined"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-04T10:39:36.566230Z",
     "start_time": "2024-10-04T10:39:36.504687Z"
    }
   },
   "source": [
    "# gradient descent\n",
    "def gradient_descent(X, y, learning_rate=0.01, epochs=100000):\n",
    "    m, n = X.shape\n",
    "    theta = np.zeros(n)\n",
    "    for _ in range(epochs):\n",
    "        y_pred = X @ theta\n",
    "        gradients = (1/m) * X.T @ (y_pred - y)\n",
    "        theta -= learning_rate * gradients\n",
    "    return theta\n",
    "\n",
    "# Adding a column of ones to X_sample for the bias term\n",
    "X_sample_with_bias = np.c_[np.ones(X_sample.shape[0]), X_sample]\n",
    "X_test_sample_with_bias = np.c_[np.ones(X_test_sample.shape[0]), X_test_sample]\n",
    "\n",
    "theta_gd = gradient_descent(X_sample_with_bias, y_sample)\n",
    "y_pred_gd = X_test_sample_with_bias @ theta_gd\n",
    "print(theta_gd)"
   ],
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "can't multiply sequence by non-int of type 'float'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[17], line 15\u001B[0m\n\u001B[0;32m     12\u001B[0m X_sample_with_bias \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mc_[np\u001B[38;5;241m.\u001B[39mones(X_sample\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m0\u001B[39m]), X_sample]\n\u001B[0;32m     13\u001B[0m X_test_sample_with_bias \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mc_[np\u001B[38;5;241m.\u001B[39mones(X_test_sample\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m0\u001B[39m]), X_test_sample]\n\u001B[1;32m---> 15\u001B[0m theta_gd \u001B[38;5;241m=\u001B[39m gradient_descent(X_sample_with_bias, y_sample)\n\u001B[0;32m     16\u001B[0m y_pred_gd \u001B[38;5;241m=\u001B[39m X_test_sample_with_bias \u001B[38;5;241m@\u001B[39m theta_gd\n\u001B[0;32m     17\u001B[0m \u001B[38;5;28mprint\u001B[39m(theta_gd)\n",
      "Cell \u001B[1;32mIn[17], line 6\u001B[0m, in \u001B[0;36mgradient_descent\u001B[1;34m(X, y, learning_rate, epochs)\u001B[0m\n\u001B[0;32m      4\u001B[0m theta \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mzeros(n)\n\u001B[0;32m      5\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m _ \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(epochs):\n\u001B[1;32m----> 6\u001B[0m     y_pred \u001B[38;5;241m=\u001B[39m X \u001B[38;5;241m@\u001B[39m theta\n\u001B[0;32m      7\u001B[0m     gradients \u001B[38;5;241m=\u001B[39m (\u001B[38;5;241m1\u001B[39m\u001B[38;5;241m/\u001B[39mm) \u001B[38;5;241m*\u001B[39m X\u001B[38;5;241m.\u001B[39mT \u001B[38;5;241m@\u001B[39m (y_pred \u001B[38;5;241m-\u001B[39m y)\n\u001B[0;32m      8\u001B[0m     theta \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m=\u001B[39m learning_rate \u001B[38;5;241m*\u001B[39m gradients\n",
      "\u001B[1;31mTypeError\u001B[0m: can't multiply sequence by non-int of type 'float'"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-383.3704364  1198.4834135  -577.09838129 1346.63961396   92.56363692\n",
      " -773.26558664 -148.50118492   64.38179525  874.79710726]\n"
     ]
    }
   ],
   "source": [
    "# closed-Form solution\n",
    "theta_closed_form = np.linalg.inv(X_sample_with_bias.T @ X_sample_with_bias) @ X_sample_with_bias.T @ y_sample\n",
    "y_pred_closed_form = X_test_sample_with_bias @ theta_closed_form\n",
    "print(theta_closed_form)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Descent MSE: 1235242.956553467\n",
      "Closed-Form MSE: 1235273.05503181\n"
     ]
    }
   ],
   "source": [
    "print(\"Gradient Descent MSE:\", mean_squared_error(y_test_sample, y_pred_gd))\n",
    "print(\"Closed-Form MSE:\", mean_squared_error(y_test_sample, y_pred_closed_form))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 3.2: Closed-form solution training complete on the larger sample.\n",
      "Coefficients: [1866.75  584.16  395.71  101.27   -8.56 -124.97  255.91    2.27 -171.51]\n"
     ]
    }
   ],
   "source": [
    "# Step 3.2 Please increase the number of samples to improve the accuracy of prediction and only use the closed form solution\n",
    "X_large_sample, X_large_test_sample, y_large_sample, y_large_test_sample = train_test_split(features_reduced, data[target_column], test_size=0.2, random_state=42)\n",
    "\n",
    "# Adding a column of ones for the bias term in the large sample\n",
    "X_large_sample_with_bias = np.c_[np.ones(X_large_sample.shape[0]), X_large_sample]\n",
    "X_large_test_sample_with_bias = np.c_[np.ones(X_large_test_sample.shape[0]), X_large_test_sample]\n",
    "\n",
    "# upgrade the normal equation\n",
    "theta_large_sample = np.linalg.inv(X_large_sample_with_bias.T @ X_large_sample_with_bias) @ X_large_sample_with_bias.T @ y_large_sample\n",
    "theta_large_sample_rounded = np.round(theta_large_sample, 2)\n",
    "\n",
    "print(f\"Step 3.2: Closed-form solution training complete on the larger sample.\")\n",
    "print(f\"Coefficients: {theta_large_sample_rounded}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given this output, we can get the optimal model: \n",
    "\n",
    "$$\n",
    "y = 1866.75 + 584.16x_1 + 395.71x_2 + 101.27x_3 - 8.56x_4 - 124.97x_5 + 255.91x_6 + 2.27x_7 - 171.51x_8\n",
    "$$\n",
    "\n",
    "Here: \n",
    "- $ y $ is the target\n",
    "- $ x_1, x_2, \\dots, x_8 $ are selected features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 3.3: Model evaluation on the testing dataset:\n",
      "Root Mean Squared Error (RMSE): 1293.0691\n",
      "Mean Squared Error (MSE): 1672027.6484\n",
      "Mean Absolute Error (MAE): 902.1377\n",
      "R-squared: 0.5935\n"
     ]
    }
   ],
   "source": [
    "# Step 3.3 Verify your model using the testing dataset and appropriate evaluation metrics\n",
    "y_large_pred_closed_form = X_large_test_sample_with_bias @ theta_large_sample\n",
    "\n",
    "mse = mean_squared_error(y_large_test_sample, y_large_pred_closed_form)\n",
    "mae = mean_absolute_error(y_large_test_sample, y_large_pred_closed_form)\n",
    "r2 = r2_score(y_large_test_sample, y_large_pred_closed_form)\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "print(f\"Step 3.3: Model evaluation on the testing dataset:\")\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse:.4f}\")\n",
    "print(f\"Mean Squared Error (MSE): {mse:.4f}\")\n",
    "print(f\"Mean Absolute Error (MAE): {mae:.4f}\")\n",
    "print(f\"R-squared: {r2:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4 Non-linear Regression\n",
    "\n",
    "In Step 1's formulation, if the price $\\lambda$ is treated as a constant and the actual value p is known, the entire formula simplifies into a function dependent on the predicted value $\\hat{p}_t$. This implies that the problem can be reframed as an optimization task concerning the prediction of $\\hat{p}_t$. Given this perspective, extending the linear regression model from Step 3 by incorporating nonlinear features to predict $\\hat{p}_t$ effectively transforms the problem into a nonlinear regression for Step 1's objective. Therefore, performing nonlinear regression on the prediction model of $\\hat{p}_t$ inherently satisfies the requirements of the nonlinear extension outlined in Step 4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4.1 Add polynomial features (squared and cubic terms)\n",
    "poly = PolynomialFeatures(degree=3, include_bias=False) \n",
    "X_poly = poly.fit_transform(features_reduced)\n",
    "\n",
    "# convert to DataFrame\n",
    "X_poly_df = pd.DataFrame(X_poly, columns=poly.get_feature_names_out(features_pca_df.columns[:-1]))\n",
    "\n",
    "# split the polynomial feature data\n",
    "X_train_poly, X_test_poly, y_train_poly, y_test_poly = train_test_split(X_poly_df, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# fit linear regression model on the polynomial features\n",
    "linear_model_poly = LinearRegression()\n",
    "linear_model_poly.fit(X_train_poly, y_train_poly)\n",
    "\n",
    "# predict on the testing data\n",
    "y_pred_poly = linear_model_poly.predict(X_test_poly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nonlinear Model Evaluation on the Testing Dataset:\n",
      "Root Mean Squared Error (RMSE): 923.4014\n",
      "Mean Squared Error (MSE): 852670.1829\n",
      "Mean Absolute Error (MAE): 600.8771\n",
      "R-squared: 0.7927\n"
     ]
    }
   ],
   "source": [
    "# evaluate the performance\n",
    "mse_poly = mean_squared_error(y_test_poly, y_pred_poly)\n",
    "mae_poly = mean_absolute_error(y_test_poly, y_pred_poly)\n",
    "r2_poly = r2_score(y_test_poly, y_pred_poly)\n",
    "rmse_poly = np.sqrt(mse_poly)\n",
    "\n",
    "print(f\"Nonlinear model evaluation on the testing dataset:\")\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse_poly:.4f}\")\n",
    "print(f\"Mean Squared Error (MSE): {mse_poly:.4f}\")\n",
    "print(f\"Mean Absolute Error (MAE): {mae_poly:.4f}\")\n",
    "print(f\"R-squared: {r2_poly:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
